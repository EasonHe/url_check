# =============================================================================
# URL æ£€æŸ¥ä»»åŠ¡æ¨¡å—
# =============================================================================
# åŠŸèƒ½ï¼š
#   - è§£æé…ç½®æ–‡ä»¶ (conf/tasks.yaml)
#   - åˆ›å»º GET/POST æ£€æŸ¥ä»»åŠ¡
#   - ä½¿ç”¨ APScheduler å®ç°å®šæ—¶è°ƒåº¦
#   - æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€æ·»åŠ /åˆ é™¤ä»»åŠ¡
#
# ä¼˜åŒ–ç‰¹æ€§ï¼š
#   - è¿æ¥æ± å¤ç”¨ï¼šå…¨å±€ requests.Session å‡å°‘ TCP æ¡æ‰‹å¼€é”€
#   - å“åº”å¤§å°é™åˆ¶ï¼šé¿å…å¤§å“åº”è€—å°½èµ„æº
#   - é‡è¯•æœºåˆ¶ï¼šç½‘ç»œå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•
#
# ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸï¼š
#   1. load_config è¯»å–é…ç½®æ–‡ä»¶
#   2. loading_task() éå†æ‰€æœ‰ä»»åŠ¡ï¼Œåˆ›å»ºæ£€æŸ¥ä»»åŠ¡
#   3. BackgroundScheduler æŒ‰ interval æ‰§è¡Œæ£€æŸ¥
#   4. æ£€æŸ¥ç»“æœä¼ é€’ç»™ cherker å¤„ç†
# =============================================================================

from apscheduler.schedulers.background import BackgroundScheduler
import yaml
import requests
from requests import exceptions
from requests.exceptions import HTTPError
from conf import config
import datetime
from view.checke_control import cherker
import time
import ssl
import socket
from urllib.parse import urlparse

# å…¨å±€ Session ç”¨äºè¿æ¥æ± å¤ç”¨
http_session = requests.Session()


def get_ssl_cert_expiry_days(url, verify=True):
    """
    ç›´æ¥è·å–SSLè¯ä¹¦å‰©ä½™å¤©æ•°

    Args:
        url: å®Œæ•´URLï¼ˆå¦‚ https://example.comï¼‰
        verify: æ˜¯å¦éªŒè¯è¯ä¹¦ï¼ˆå¦‚æœä¸ºFalseåˆ™è·³è¿‡æ£€æŸ¥ï¼‰

    Returns:
        int: å‰©ä½™å¤©æ•°ï¼Œè·å–å¤±è´¥æˆ–verify=Falseæ—¶è¿”å› None
    """
    # å¦‚æœè·³è¿‡è¯ä¹¦éªŒè¯ï¼Œåˆ™ä¸æ£€æŸ¥è¿‡æœŸæ—¶é—´
    if not verify:
        return None

    try:
        parsed = urlparse(url)
        hostname = parsed.hostname
        port = parsed.port or 443

        context = ssl.create_default_context()

        with socket.create_connection((hostname, port), timeout=5) as sock:
            with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                cert = ssock.getpeercert()
                if cert and "notAfter" in cert:
                    not_after_str = cert["notAfter"]
                    not_after = datetime.datetime.strptime(
                        not_after_str, "%b %d %H:%M:%S %Y %Z"
                    )
                    days = (not_after - datetime.datetime.now()).days
                    return days
    except Exception:
        pass
    return None


class get_method:
    """
    GET è¯·æ±‚æ£€æŸ¥ä»»åŠ¡
    """

    def __init__(
        self,
        task_name,
        url,
        headers=None,
        cookies=None,
        payload=None,
        timeout=10,
        threshold=None,
        max_response_size=None,
        retry_count=0,
        retry_delay=1,
        proxy=None,
        ssl_verify=True,
        ssl_warning_days=30,
        expect_json=False,
        json_path=None,
        json_path_value=None,
    ):
        """
        åˆå§‹åŒ– GET æ£€æŸ¥ä»»åŠ¡
        """
        self.task_name = task_name
        self.url = url
        self.header = headers
        self.payload = payload
        self.timeout = timeout
        self.cookies = cookies
        self.threshold = threshold
        self.max_response_size = max_response_size
        self.retry_count = retry_count
        self.retry_delay = retry_delay
        self.proxy = proxy
        self.ssl_verify = ssl_verify
        self.ssl_warning_days = ssl_warning_days
        self.expect_json = expect_json
        self.json_path = json_path
        self.json_path_value = json_path_value

    def get_instan(self):
        """
        æ‰§è¡Œ GET è¯·æ±‚æ£€æŸ¥
        """
        last_error = None
        for attempt in range(self.retry_count + 1):
            try:
                data = {}
                now_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                # å¤„ç† proxy é…ç½®ï¼Œæ”¯æŒ __HOST__ å…³é”®å­—
                proxy = self.proxy
                if proxy:
                    from conf import config

                    host_ip = getattr(config, "HOST_IP", "host.docker.internal")
                    proxy = proxy.replace("__HOST__", host_ip)

                proxies = {"http": proxy, "https": proxy} if proxy else None

                # SSL éªŒè¯é…ç½®
                verify = self.ssl_verify

                r = http_session.get(
                    self.url,
                    headers=self.header,
                    cookies=self.cookies,
                    data=self.payload,
                    timeout=self.timeout,
                    stream=True,
                    proxies=proxies,
                    verify=verify,
                )
                r.raise_for_status()
                r.encoding = "utf-8"

                # SSL è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥ï¼ˆä½¿ç”¨ç‹¬ç«‹å‡½æ•°ï¼‰
                ssl_expiry_days = get_ssl_cert_expiry_days(self.url, verify=verify)
                if ssl_expiry_days is not None:
                    print(f"SSL è¯ä¹¦å‰©ä½™ {ssl_expiry_days} å¤©")

                    # æ›´æ–° Prometheus æŒ‡æ ‡
                    from view.checke_control import url_check_ssl_expiry_days

                    url_check_ssl_expiry_days.labels(
                        task_name=self.task_name, method="get"
                    ).set(ssl_expiry_days)

                    # è¯ä¹¦å³å°†è¿‡æœŸå‘Šè­¦
                    if ssl_expiry_days < self.ssl_warning_days:
                        print(
                            f"è­¦å‘Š: {self.task_name} SSL è¯ä¹¦å°†åœ¨ {ssl_expiry_days} å¤©åè¿‡æœŸ"
                        )

                # æ›´æ–° SSL éªŒè¯çŠ¶æ€æŒ‡æ ‡
                from view.checke_control import url_check_ssl_verified

                url_check_ssl_verified.labels(
                    task_name=self.task_name, method="get", verified=str(verify).lower()
                ).inc()

                content = ""
                if self.max_response_size:
                    content_len = len(r.content)
                    if content_len > self.max_response_size:
                        print(
                            f"è­¦å‘Š: {self.task_name} å“åº”å¤§å° {content_len} å­—èŠ‚è¶…è¿‡é™åˆ¶ {self.max_response_size}ï¼Œè·³è¿‡å†…å®¹è§£æ"
                        )
                        content = ""
                    else:
                        content = r.text
                else:
                    content = r.text

                retime = r.elapsed.total_seconds() * 1000
                statuscode = r.status_code
                data = {
                    "url_name": self.task_name,
                    "url": self.url,
                    "stat_code": statuscode,
                    "timeout": 0,
                    "resp_time": retime,
                    "contents": content,
                    "time": now_time,
                    "threshold": self.threshold,
                    "expect_json": self.expect_json,
                    "json_path": self.json_path,
                    "json_path_value": self.json_path_value,
                    "ssl_expiry_days": ssl_expiry_days,
                    "ssl_warning_days": self.ssl_warning_days,
                }
                print(data)
                ck = cherker(method="get")
                ck.make_data(data)
                return

            except HTTPError as e:
                last_error = e
                # ä¿®å¤ï¼šä½¿ç”¨ is not None è€Œä¸æ˜¯ä¾èµ–å¸ƒå°”å€¼åˆ¤æ–­
                # å› ä¸º Response å¯¹è±¡çš„ __bool__ æ–¹æ³•åœ¨ HTTP é”™è¯¯æ—¶è¿”å› False
                status_code = e.response.status_code if e.response is not None else 0
                print(f"è­¦å‘Š: {self.task_name} HTTPé”™è¯¯: {status_code} {e}")
                data = {
                    "url_name": self.task_name,
                    "url": self.url,
                    "stat_code": status_code,
                    "timeout": 0,
                    "resp_time": 0,
                    "contents": str(e),
                    "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "threshold": self.threshold,
                    "expect_json": self.expect_json,
                    "json_path": self.json_path,
                    "json_path_value": self.json_path_value,
                    "ssl_expiry_days": None,
                    "ssl_warning_days": self.ssl_warning_days,
                }
                print(data)
                ck = cherker(method="get")
                ck.make_data(data)
                return

            except Exception as e:
                last_error = e
                if attempt < self.retry_count:
                    print(
                        f"ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚å¤±è´¥ï¼Œ{self.retry_delay} ç§’åé‡è¯•: {e}"
                    )
                    time.sleep(self.retry_delay)

        print(f"è­¦å‘Š: {self.task_name} é‡è¯• {self.retry_count} æ¬¡å‡å¤±è´¥: {last_error}")
        data = {
            "url_name": self.task_name,
            "url": self.url,
            "threshold": self.threshold,
            "timeout": 1,
            "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "expect_json": self.expect_json,
            "json_path": self.json_path,
            "json_path_value": self.json_path_value,
        }
        print(data)
        ck = cherker(method="get")
        ck.make_data(data)


class post_method:
    """
    POST è¯·æ±‚æ£€æŸ¥ä»»åŠ¡
    """

    def __init__(
        self,
        task_name,
        url,
        headers=None,
        cookies=None,
        payload=None,
        timeout=None,
        threshold=None,
        max_response_size=None,
        retry_count=0,
        retry_delay=1,
        proxy=None,
        ssl_verify=True,
        ssl_warning_days=30,
        expect_json=False,
        json_path=None,
        json_path_value=None,
    ):
        """
        åˆå§‹åŒ– POST æ£€æŸ¥ä»»åŠ¡
        """
        self.task_name = task_name
        self.url = url
        self.header = headers
        self.payload = payload
        self.timeout = timeout
        self.cookies = cookies
        self.threshold = threshold
        self.max_response_size = max_response_size
        self.retry_count = retry_count
        self.retry_delay = retry_delay
        self.proxy = proxy
        self.ssl_verify = ssl_verify
        self.ssl_warning_days = ssl_warning_days
        self.expect_json = expect_json
        self.json_path = json_path
        self.json_path_value = json_path_value

    def post_instan(self):
        """
        æ‰§è¡Œ POST è¯·æ±‚æ£€æŸ¥
        """
        last_error = None
        for attempt in range(self.retry_count + 1):
            try:
                data = {}

                # å¤„ç† proxy é…ç½®ï¼Œæ”¯æŒ __HOST__ å…³é”®å­—
                proxy = self.proxy
                if proxy:
                    from conf import config

                    host_ip = getattr(config, "HOST_IP", "host.docker.internal")
                    proxy = proxy.replace("__HOST__", host_ip)

                proxies = {"http": proxy, "https": proxy} if proxy else None
                r = http_session.post(
                    self.url,
                    headers=self.header,
                    cookies=self.cookies,
                    data=self.payload,
                    timeout=self.timeout,
                    stream=True,
                    proxies=proxies,
                    verify=self.ssl_verify,
                )
                r.raise_for_status()
                r.encoding = "utf-8"

                # SSL è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥ï¼ˆä½¿ç”¨ç‹¬ç«‹å‡½æ•°ï¼‰
                ssl_expiry_days = get_ssl_cert_expiry_days(
                    self.url, verify=self.ssl_verify
                )
                if ssl_expiry_days is not None:
                    print(f"SSL è¯ä¹¦å‰©ä½™ {ssl_expiry_days} å¤©")

                    from view.checke_control import url_check_ssl_expiry_days

                    url_check_ssl_expiry_days.labels(
                        task_name=self.task_name, method="post"
                    ).set(ssl_expiry_days)

                    if ssl_expiry_days < self.ssl_warning_days:
                        print(
                            f"è­¦å‘Š: {self.task_name} SSL è¯ä¹¦å°†åœ¨ {ssl_expiry_days} å¤©åè¿‡æœŸ"
                        )

                # æ›´æ–° SSL éªŒè¯çŠ¶æ€æŒ‡æ ‡
                from view.checke_control import url_check_ssl_verified

                url_check_ssl_verified.labels(
                    task_name=self.task_name,
                    method="post",
                    verified=str(self.ssl_verify).lower(),
                ).inc()

                content = ""
                if self.max_response_size:
                    content_len = len(r.content)
                    if content_len > self.max_response_size:
                        print(
                            f"è­¦å‘Š: {self.task_name} å“åº”å¤§å° {content_len} å­—èŠ‚è¶…è¿‡é™åˆ¶ {self.max_response_size}ï¼Œè·³è¿‡å†…å®¹è§£æ"
                        )
                        content = ""
                    else:
                        content = r.text
                else:
                    content = r.text

                retime = r.elapsed.total_seconds() * 1000
                statuscode = r.status_code
                data = {
                    "url_name": self.task_name,
                    "url": self.url,
                    "stat_code": statuscode,
                    "timeout": 0,
                    "resp_time": retime,
                    "contents": content,
                    "threshold": self.threshold,
                    "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "expect_json": self.expect_json,
                    "json_path": self.json_path,
                    "json_path_value": self.json_path_value,
                    "ssl_expiry_days": ssl_expiry_days,
                    "ssl_warning_days": self.ssl_warning_days,
                }
                print(data)
                ck = cherker(method="post")
                ck.make_data(data)
                return

            except HTTPError as e:
                last_error = e
                # ä¿®å¤ï¼šä½¿ç”¨ is not None è€Œä¸æ˜¯ä¾èµ–å¸ƒå°”å€¼åˆ¤æ–­
                status_code = e.response.status_code if e.response is not None else 0
                print(f"è­¦å‘Š: {self.task_name} HTTPé”™è¯¯: {status_code} {e}")
                data = {
                    "url_name": self.task_name,
                    "url": self.url,
                    "stat_code": status_code,
                    "timeout": 0,
                    "resp_time": 0,
                    "contents": str(e),
                    "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "threshold": self.threshold,
                    "expect_json": self.expect_json,
                    "json_path": self.json_path,
                    "json_path_value": self.json_path_value,
                    "ssl_expiry_days": None,
                    "ssl_warning_days": self.ssl_warning_days,
                }
                print(data)
                ck = cherker(method="post")
                ck.make_data(data)
                return

            except Exception as e:
                last_error = e
                if attempt < self.retry_count:
                    print(
                        f"ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚å¤±è´¥ï¼Œ{self.retry_delay} ç§’åé‡è¯•: {e}"
                    )
                    time.sleep(self.retry_delay)

        print(f"è­¦å‘Š: {self.task_name} é‡è¯• {self.retry_count} æ¬¡å‡å¤±è´¥: {last_error}")
        data = {
            "url_name": self.task_name,
            "url": self.url,
            "threshold": self.threshold,
            "timeout": 1,
            "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "expect_json": self.expect_json,
            "json_path": self.json_path,
            "json_path_value": self.json_path_value,
        }
        print(data)
        ck = cherker(method="post")
        ck.make_data(data)


class load_config:
    """
    é…ç½®åŠ è½½ä¸ä»»åŠ¡è°ƒåº¦ç®¡ç†å™¨
    """

    def __init__(self):
        with open(config.tasks_yaml, "r", encoding="utf-8") as f:
            self.tasks = yaml.safe_load(f)

        from apscheduler.executors.pool import ThreadPoolExecutor

        executors = {"default": ThreadPoolExecutor(max_workers=5)}
        job_defaults = {"coalesce": False, "max_instances": 3, "misfire_grace_time": 60}
        self.sched = BackgroundScheduler(executors=executors, job_defaults=job_defaults)

    def config_set(self, task):
        """
        è§£æå•ä¸ªä»»åŠ¡çš„é…ç½®
        """
        url = task.get("url")
        threshold = task.get("threshold", {})
        timeout = task.get("timeout", 10)
        interval = task.get("interval", 10)
        headers = task.get("headers")
        cookies = task.get("cookies")
        payload = task.get("payload")
        max_response_size = task.get("max_response_size")
        retry = task.get("retry", {})
        retry_count = retry.get("count", 0)
        retry_delay = retry.get("delay", 1)
        proxy = task.get("proxy")

        # SSL é…ç½®
        ssl = task.get("ssl", {})
        ssl_verify = ssl.get("verify", True)
        ssl_warning_days = ssl.get("warning_days", 30)

        # JSON éªŒè¯é…ç½®
        expect_json = task.get("expect_json", False)
        json_path = task.get("json_path")
        json_path_value = task.get("json_path_value")

        if "stat_code" not in threshold:
            threshold["stat_code"] = 200

        return {
            "Url": url,
            "Headers": headers,
            "Cookies": cookies,
            "Payload": payload,
            "Interval": interval,
            "Timeout": timeout,
            "threshold": threshold,
            "max_response_size": max_response_size,
            "retry_count": retry_count,
            "retry_delay": retry_delay,
            "proxy": proxy,
            "ssl_verify": ssl_verify,
            "ssl_warning_days": ssl_warning_days,
            "expect_json": expect_json,
            "json_path": json_path,
            "json_path_value": json_path_value,
        }

    def add_task(self, task):
        """
        æ·»åŠ å•ä¸ªæ£€æŸ¥ä»»åŠ¡åˆ°è°ƒåº¦å™¨
        """
        task_name = task.get("name")
        method = task.get("method", "get")

        if method == "post":
            print("task {} post method".format(task_name))
            conf = self.config_set(task)

            task_obj = post_method(
                task_name=task_name,
                url=conf["Url"],
                headers=conf["Headers"],
                cookies=conf["Cookies"],
                payload=conf["Payload"],
                timeout=conf["Timeout"],
                threshold=conf["threshold"],
                max_response_size=conf["max_response_size"],
                retry_count=conf["retry_count"],
                retry_delay=conf["retry_delay"],
                proxy=conf["proxy"],
                ssl_verify=conf["ssl_verify"],
                ssl_warning_days=conf["ssl_warning_days"],
                expect_json=conf["expect_json"],
                json_path=conf["json_path"],
                json_path_value=conf["json_path_value"],
            )
            self.sched.add_job(
                task_obj.post_instan,
                "interval",
                seconds=conf["Interval"],
                id=task_name,
                max_instances=10,
                replace_existing=True,
            )

        elif method == "get":
            print("task {} get method".format(task_name))
            conf = self.config_set(task)

            task_obj = get_method(
                task_name=task_name,
                url=conf["Url"],
                headers=conf["Headers"],
                cookies=conf["Cookies"],
                payload=conf["Payload"],
                timeout=conf["Timeout"],
                threshold=conf["threshold"],
                max_response_size=conf["max_response_size"],
                retry_count=conf["retry_count"],
                retry_delay=conf["retry_delay"],
                proxy=conf["proxy"],
                ssl_verify=conf["ssl_verify"],
                ssl_warning_days=conf["ssl_warning_days"],
                expect_json=conf["expect_json"],
                json_path=conf["json_path"],
                json_path_value=conf["json_path_value"],
            )
            self.sched.add_job(
                task_obj.get_instan,
                "interval",
                seconds=conf["Interval"],
                id=task_name,
                max_instances=10,
                replace_existing=True,
            )

        else:
            print(
                "{}........é…ç½®æ–‡ä»¶é”™è¯¯:è¯·æ£€æŸ¥ä½ çš„çš„è¯·æ±‚æ–¹æ³•ï¼Œmethod = post ,method = get".format(
                    task_name
                )
            )

    def loading_task(self):
        """
        åŠ è½½æ‰€æœ‰é…ç½®å¹¶å¯åŠ¨è°ƒåº¦å™¨
        """
        task_list = self.tasks.get("tasks", [])
        for task in task_list:
            self.add_task(task=task)
        self.sched.start()
        print("start")

    def get_jobs(self):
        job_list = []
        for instan in self.sched.get_jobs():
            job_list.append(instan.id)
        return job_list

    def remove_job(self, task_name):
        self.sched.remove_job(task_name)

    def stop_job(self, task_name):
        self.sched.pause_job(job_id=task_name)
        return True

    def resume_job(self, task_name):
        self.sched.resume_job(job_id=task_name)
        return True

    def shut_sched(self):
        self.sched.shutdown()
        return True

    def add_job(self, task_info):
        """
        åŠ¨æ€æ·»åŠ ä»»åŠ¡ï¼ˆé€šè¿‡ APIï¼‰
        """
        job_list = self.get_jobs()
        print(job_list)
        task_name = task_info.get("section")
        if task_name not in job_list:
            task = {
                "name": task_name,
                "url": task_info.get("url"),
                "method": task_info.get("method", "get"),
                "timeout": task_info.get("timeout", 10),
                "interval": task_info.get("interval", 10),
                "headers": task_info.get("headers"),
                "cookies": task_info.get("cookies"),
                "payload": task_info.get("payload"),
                "threshold": task_info.get("threshold", {"stat_code": 200}),
            }
            print([t.get("name") for t in self.tasks.get("tasks", [])])
            self.tasks["tasks"].append(task)
            self.add_task(task=task)
            return "add success"
        else:
            print(task_name, "is exits")
            return False

    def safe_reload_config(self):
        """
        å®‰å…¨é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
        """
        import logging

        logger = logging.getLogger(__name__)
        try:
            with open(config.tasks_yaml, "r", encoding="utf-8") as f:
                new_tasks = yaml.safe_load(f)
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
            return False

        if not hasattr(self, "tasks"):
            logger.warning("tasks æœªåˆå§‹åŒ–ï¼Œè·³è¿‡é‡è½½")
            return False

        old_task_names = set(t.get("name") for t in self.tasks.get("tasks", []))
        new_task_names = set(t.get("name") for t in new_tasks.get("tasks", []))

        for name in old_task_names - new_task_names:
            try:
                job = self.sched.get_job(name)
                if job:
                    self.sched.remove_job(name)
                    logger.info(f"å·²ç§»é™¤ä»»åŠ¡: {name}")
            except Exception as e:
                logger.error(f"ç§»é™¤ä»»åŠ¡ {name} å¤±è´¥: {e}")

        for task in new_tasks.get("tasks", []):
            try:
                name = task.get("name")
                job = self.sched.get_job(name)
                if job:
                    self.sched.remove_job(name)
                self.add_task(task)
                logger.info(f"å·²æ›´æ–°ä»»åŠ¡: {name}")
            except Exception as e:
                logger.error(f"ä»»åŠ¡ {name} åŠ è½½å¤±è´¥: {e}")
                continue

        self.tasks = new_tasks
        return True

    def start_sched(self):
        self.sched.start()


class ReportTask:
    """å®šæ—¶æ±‡æ€»æŠ¥å‘Šä»»åŠ¡"""

    def __init__(self, interval_hours=2):
        self.interval_hours = interval_hours

    @staticmethod
    def _parse_alerts(alarm):
        """å°† alarm å­—å…¸è½¬æ¢ä¸ºå¯è¯»å‘Šè­¦åˆ—è¡¨"""
        alarm = alarm or {}
        labels = []
        if alarm.get("code_warm") == 1:
            labels.append("çŠ¶æ€ç ")
        if alarm.get("timeout_warm") == 1:
            labels.append("è¶…æ—¶")
        if alarm.get("math_warm") == 1:
            labels.append("å…³é”®å­—")
        if alarm.get("json_warm") == 1:
            labels.append("JSONè·¯å¾„")
        if alarm.get("delay_warm") == 1:
            labels.append("å“åº”æ—¶é—´")
        if alarm.get("ssl_warm") == 1:
            labels.append("SSLè¯ä¹¦")
        return labels

    @staticmethod
    def _extract_latest_time(data, task_name):
        """ä»æŒä¹…åŒ–æ•°æ®ä¸­æå–ä»»åŠ¡æœ€è¿‘ä¸€æ¬¡æ£€æŸ¥æ—¶é—´"""
        latest = None
        for key, records in data.items():
            if key in {"alarm", "alarm_notified", "last_alert_time", "last_resp_time"}:
                continue
            if not isinstance(records, list):
                continue

            for item in records:
                if not isinstance(item, dict):
                    continue
                task_block = item.get(task_name)
                if not isinstance(task_block, dict):
                    continue
                time_str = task_block.get("time")
                if not time_str:
                    continue
                try:
                    dt = datetime.datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
                except Exception:
                    continue
                if latest is None or dt > latest:
                    latest = dt
        return latest

    def generate_report(self):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        import pickle
        import os

        report_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        data_dir = "data"
        normal_tasks = []
        current_alert_tasks = []
        notified_alert_tasks = []
        no_data_tasks = []
        stale_tasks = []
        failed_tasks = []

        configured_tasks = []
        task_intervals = {}
        try:
            with open(config.tasks_yaml, "r", encoding="utf-8") as f:
                task_conf = yaml.safe_load(f) or {}
            configured_tasks = task_conf.get("tasks", [])
            for task in configured_tasks:
                name = task.get("name")
                if name:
                    task_intervals[name] = int(task.get("interval", 10))
        except Exception as e:
            return (
                "ğŸ“Š URLç›‘æ§æ±‡æ€»æŠ¥å‘Š",
                f"æ±‡æ€»æ—¶é—´: {report_time}\nè¯»å–ä»»åŠ¡é…ç½®å¤±è´¥: {e}",
            )

        total_tasks = len([t for t in configured_tasks if t.get("name")])

        for task in configured_tasks:
            task_name = task.get("name")
            if not task_name:
                continue

            filepath = os.path.join(data_dir, f"{task_name}.pkl")
            if not os.path.exists(filepath):
                no_data_tasks.append(f"- {task_name}")
                continue

            try:
                with open(filepath, "rb") as f:
                    data = pickle.load(f)
            except Exception as e:
                failed_tasks.append(f"- {task_name}: {e}")
                continue

            current_alerts = self._parse_alerts(data.get("alarm", {}))
            notified_alerts = self._parse_alerts(
                data.get("alarm_notified", data.get("alarm", {}))
            )

            if current_alerts:
                current_alert_tasks.append(
                    f"- {task_name}: {', '.join(current_alerts)}"
                )
            else:
                normal_tasks.append(f"- {task_name}")

            if notified_alerts:
                notified_alert_tasks.append(
                    f"- {task_name}: {', '.join(notified_alerts)}"
                )

            latest_time = self._extract_latest_time(data, task_name)
            if latest_time is None:
                stale_tasks.append(f"- {task_name}: æ— æœ‰æ•ˆæ£€æŸ¥æ—¶é—´")
            else:
                interval = task_intervals.get(task_name, 10)
                stale_seconds = max(interval * 3, 180)
                age = (datetime.datetime.now() - latest_time).total_seconds()
                if age > stale_seconds:
                    stale_tasks.append(
                        f"- {task_name}: æœ€åæ£€æŸ¥ {latest_time.strftime('%Y-%m-%d %H:%M:%S')}"
                    )

        msg = f"æ±‡æ€»æ—¶é—´: {report_time}\n"
        msg += f"ç›‘æ§å‘¨æœŸ: {self.interval_hours}å°æ—¶\n"
        msg += f"é…ç½®ä»»åŠ¡æ€»æ•°: {total_tasks}ä¸ª\n"
        msg += f"æœ‰çŠ¶æ€æ–‡ä»¶: {total_tasks - len(no_data_tasks)}ä¸ª\n"
        msg += f"æ— çŠ¶æ€æ–‡ä»¶: {len(no_data_tasks)}ä¸ª\n\n"

        msg += f"âœ… å½“å‰æ­£å¸¸: {len(normal_tasks)}ä¸ª\n"
        for task_line in normal_tasks:
            msg += task_line + "\n"

        msg += f"\nâš ï¸ å½“å‰å¼‚å¸¸(æŒ‰ alarm): {len(current_alert_tasks)}ä¸ª\n"
        for task_line in current_alert_tasks:
            msg += task_line + "\n"

        msg += f"\nğŸ“£ å·²é€šçŸ¥å¼‚å¸¸(æŒ‰ alarm_notified): {len(notified_alert_tasks)}ä¸ª\n"
        for task_line in notified_alert_tasks:
            msg += task_line + "\n"

        msg += f"\nâ“ æ— çŠ¶æ€æ–‡ä»¶: {len(no_data_tasks)}ä¸ª\n"
        for task_line in no_data_tasks:
            msg += task_line + "\n"

        msg += f"\nğŸ•’ æ•°æ®è¿‡æœŸ/æ— æ—¶é—´: {len(stale_tasks)}ä¸ª\n"
        for task_line in stale_tasks:
            msg += task_line + "\n"

        if failed_tasks:
            msg += f"\nâ›” è¯»å–å¤±è´¥: {len(failed_tasks)}ä¸ª\n"
            for task_line in failed_tasks:
                msg += task_line + "\n"

        return "ğŸ“Š URLç›‘æ§æ±‡æ€»æŠ¥å‘Š", msg

    def send_report(self):
        """å‘é€æ±‡æ€»æŠ¥å‘Š"""
        from conf import config

        if not config.report_enabled:
            print("å®šæ—¶æ±‡æ€»æŠ¥å‘Šæœªå¯ç”¨")
            return

        print("å¼€å§‹ç”Ÿæˆå®šæ—¶æ±‡æ€»æŠ¥å‘Š...")
        title, msg = self.generate_report()

        if config.report_dingding_enabled:
            from view.dingding import ding_report

            ding_report(title=title, msg=msg)
            print("é’‰é’‰æ±‡æ€»æŠ¥å‘Šå·²å‘é€")

        if config.report_mail_enabled:
            pass

        print("å®šæ—¶æ±‡æ€»æŠ¥å‘Šå‘é€å®Œæˆ")


def add_report_job(sched, interval_hours=2):
    """æ·»åŠ å®šæ—¶æ±‡æ€»æŠ¥å‘Šä»»åŠ¡"""
    from conf import config

    if not config.report_enabled:
        print("å®šæ—¶æ±‡æ€»æŠ¥å‘Šæœªå¯ç”¨ï¼Œè·³è¿‡")
        return

    report_task = ReportTask(interval_hours=interval_hours)
    sched.add_job(
        report_task.send_report,
        "interval",
        hours=interval_hours,
        id="report_task",
        replace_existing=True,
    )
    print(f"å®šæ—¶æ±‡æ€»æŠ¥å‘Šä»»åŠ¡å·²å¯åŠ¨ï¼Œå‘¨æœŸ: {interval_hours}å°æ—¶")
